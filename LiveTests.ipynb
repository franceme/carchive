{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Warm Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,sys,json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from glob import glob as re\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade funbelts\n",
    "!{sys.executable} -m pip install --upgrade python-git-info\n",
    "!{sys.executable} -m pip install --upgrade deczoo\n",
    "import funbelts as ut\n",
    "from gitinfo import get_git_info as get_git\n",
    "from deczoo import *\n",
    "\n",
    "import Semgrep as semgrep\n",
    "import Cryptolation as cryptolation\n",
    "import Bandit as bandit\n",
    "import DLint as dlint\n",
    "import Licma as licma\n",
    "\n",
    "import PyScan as pyscan\n",
    "import PyMetrics as pymetrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From tasks.py (Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os,sys\n",
    "from invoke import task\n",
    "\n",
    "\n",
    "@task\n",
    "def gitr(c):\n",
    "\tfor x in [\n",
    "\t\t'git config --global user.email \"EMAIL\"',\n",
    "\t\t'git config --global user.name \"UserName (dev@lite)\"'\n",
    "\t]:\n",
    "\t\tprint(x);os.system(x)\n",
    "\n",
    "@task\n",
    "def cleanenv(c):\n",
    "\tfor x in [\n",
    "\t\t'CachedExtensions/',\n",
    "\t\t'CachedExtensionVSIXs/',\n",
    "\t\t'User/',\n",
    "\t\t'Machine/',\n",
    "\t\t'extensions/',\n",
    "\t\t'logs/',\n",
    "\t\t'coder.json',\n",
    "\t\t'machineid',\n",
    "\t]:\n",
    "\t\tx = \"yes|rm -r \" + str(x)\n",
    "\t\tprint(x);os.system(x)\n",
    "\n",
    "@task\n",
    "def execute(c):\n",
    "\tprint(\"Executing\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From make.py -> tasks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, sys, pwd, re, uuid, pwd, json, time, platform, dis\n",
    "from abc import ABC, abstractmethod\n",
    "from collections.abc import Callable\n",
    "from typing import List, Any\n",
    "from glob import glob\n",
    "from copy import copy as dc\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tcmd, args = [], set(map(lambda x: x.lower().strip(), sys.argv))\n",
    "\tif \"install\" in args:\n",
    "\t\tinstall = lambda name: os.system(f\"{sys.executable} -m pip install --upgrade {name}\")\n",
    "\t\t[install(x) for x in ['pandas', 'funbelts']]\n",
    "\n",
    "import pandas as pd\n",
    "from funbelts import progressBar, isMac, mac_addr as getMacAddr, excelwriter, run as try_fail, wait_for, user, clean_string as filterForName\n",
    "import funbelts as ut\n",
    "\n",
    "\n",
    "def get_file_output(path, suffix):\n",
    "\toutput = filterForName(path.replace(\".py\", \"\"))\n",
    "\treturn output + suffix\n",
    "\n",
    "\n",
    "docker_base = 'docker' if isMac() else 'sudo docker'\n",
    "\n",
    "\n",
    "def mac_addr():\n",
    "\tfile_name = \"MAC_ADDRESS.txt\"\n",
    "\n",
    "\tif not os.path.exists(file_name):\n",
    "\t\twith open(file_name, 'w+') as writer:\n",
    "\t\t\twriter.write(getMacAddr())\n",
    "\n",
    "\treturn file_name\n",
    "\n",
    "def rules():\n",
    "\timport Bandit as bandit\n",
    "\timport Licma as licma\n",
    "\timport DLint as dlint\n",
    "\timport Semgrep as semgrep\n",
    "\tfor scan in [bandit.application(), dlint.application(), licma.application(), semgrep.application()]:\n",
    "\t\twith open(scan.name()+\"_ruleset.csv\",\"w+\") as writer:\n",
    "\t\t\twriter.write(f\"{scan.name()} ID,Cryptolation ID\\n\")\n",
    "\t\t\ttry:\n",
    "\t\t\t\tfor key,value in scan.rules().items():\n",
    "\t\t\t\t\tif value != -1:\n",
    "\t\t\t\t\t\twriter.write(f\"{key},{value}\\n\")\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(e)\n",
    "\t\t\t\tpass\n",
    "\n",
    "def indicateBase():\n",
    "\tfile_name = str('MAC' if isMac() else 'LINUX') + \".txt\"\n",
    "\ttry_fail(f\"touch {file_name}\")\n",
    "\n",
    "\tmac_addr()\n",
    "\treturn file_name\n",
    "\n",
    "\n",
    "def get_docker_connect():\n",
    "\tif os.path.exists(f\"MAC.txt\"):\n",
    "\t\trunning = f\"/Users/{user()}/.docker/run/docker.sock\"\n",
    "\telse:\n",
    "\t\trunning = \"/var/run/docker.sock\"\n",
    "\treturn running\n",
    "\n",
    "\n",
    "class BaseApplicationClass(ABC):\n",
    "\n",
    "\tdef __init__(self, name: str = None, links={}):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.__name = name\n",
    "\t\t#self.__version = version\n",
    "\t\tself.__links = links\n",
    "\t\tself.dl_folder = None\n",
    "\t\tself.__modules = None\n",
    "\t\tself.dl_name = None\n",
    "\t\tself.downloaded_files = []\n",
    "\t\tself.hash_files = {}\n",
    "\n",
    "\tdef lazy_scanning(self):\n",
    "\t\treturn False\n",
    "\n",
    "\tdef name(self, compare: str = None):\n",
    "\t\toutput = self.__name\n",
    "\t\tif compare:\n",
    "\t\t\toutput = compare.lower() == output.lower()\n",
    "\t\treturn output\n",
    "\n",
    "\tdef version(self, setting_version: str = None):\n",
    "\t\tif setting_version:\n",
    "\t\t\tself.__version = setting_version\n",
    "\t\treturn self.__version\n",
    "\n",
    "\t@property\n",
    "\tdef links(self):\n",
    "\t\treturn dc(self.__links)\n",
    "\n",
    "\t@property\n",
    "\t@abstractmethod\n",
    "\tdef dl_link(self):\n",
    "\t\tpass\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef sha256sum(filename):\n",
    "\t\t#https://stackoverflow.com/questions/22058048/hashing-a-file-in-python\n",
    "\t\timport hashlib\n",
    "\t\th  = hashlib.sha256()\n",
    "\t\tb  = bytearray(128*1024)\n",
    "\t\tmv = memoryview(b)\n",
    "\t\twith open(filename, 'rb', buffering=0) as f:\n",
    "\t\t\tfor n in iter(lambda : f.readinto(mv), 0):\n",
    "\t\t\t\th.update(mv[:n])\n",
    "\t\treturn str(h.hexdigest())\n",
    "\n",
    "\tdef verify(self, file_name):\n",
    "\t\tprint(f\"Verifing the file {file_name}\")\n",
    "\t\tif file_name not in self.hash_files.keys():\n",
    "\t\t\treturn False\n",
    "\t\tprint(f\"Current Hash: {BaseApplicationClass.sha256sum(file_name)}\")\n",
    "\t\treturn BaseApplicationClass.sha256sum(file_name) == self.hash_files[file_name]\n",
    "\n",
    "\tdef download(self):\n",
    "\t\toutput = True\n",
    "\n",
    "\t\tif self.dl_link is None:\n",
    "\t\t\treturn True\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tfoil_name = self.dl_link.split('/')[-1]\n",
    "\t\t\tdownload_name = \"DL_\" + self.name() + \"_\" + foil_name\n",
    "\n",
    "\t\t\tif not os.path.exists(download_name):\n",
    "\t\t\t\trun_cmd = f\"wget {self.dl_link};mkdir {download_name};unzip {foil_name} -d {download_name}\"\n",
    "\t\t\t\tprint(run_cmd);try_fail(run_cmd)\n",
    "\t\t\t\tif not self.verify(foil_name):\n",
    "\t\t\t\t\tprint(f\"The archived file {foil_name} does not match the saved hash\")\n",
    "\t\t\t\t\tsys.exit(-5)\n",
    "\t\t\t\tos.remove(foil_name)\n",
    "\n",
    "\t\t\tfldrs = os.listdir(download_name)[0]\n",
    "\t\t\tself.dl_folder = os.path.join(download_name, fldrs)\n",
    "\t\t\tself.downloaded_files += [download_name]\n",
    "\t\texcept:\n",
    "\t\t\toutput = False\n",
    "\t\t\tpass\n",
    "\n",
    "\t\treturn output\n",
    "\n",
    "\t@property\n",
    "\tdef dl_files(self):\n",
    "\t\treturn self.downloaded_files\n",
    "\n",
    "\t@property\n",
    "\t@abstractmethod\n",
    "\tdef modules(self):\n",
    "\t\tpass\n",
    "\n",
    "\t@property\n",
    "\tdef get_modules(self):\n",
    "\t\tif self.__modules is None:\n",
    "\t\t\tself.__modules = self.modules\n",
    "\t\treturn self.__modules\n",
    "\n",
    "\t@abstractmethod\n",
    "\tdef install(self):\n",
    "\t\tpass\n",
    "\n",
    "\t@abstractmethod\n",
    "\tdef scan(self, file_name: str, isDir: bool = False) -> (pd.DataFrame, int):\n",
    "\t\tpass\n",
    "\n",
    "\t@abstractmethod\n",
    "\tdef mapp(self,\n",
    "\t\t\tself_frame: pd.DataFrame,\n",
    "\t\t\tprojectName: str,\n",
    "\t\t\tcolumns: List[str],\n",
    "\t\t\tgen,\n",
    "\t\t\ttime_taken: str = None):\n",
    "\t\tpass\n",
    "\n",
    "\t@abstractmethod\n",
    "\tdef clean(self) -> List[str]:\n",
    "\t\tpass\n",
    "\n",
    "\t@abstractmethod\n",
    "\tdef mapp_rule_id(self, rule_id: str) -> str:\n",
    "\t\tpass\n",
    "\n",
    "\tdef current_user(self):\n",
    "\t\treturn user()\n",
    "\n",
    "\tdef base_is_mac(self):\n",
    "\t\treturn os.path.exists(f\"MAC.txt\")\n",
    "\n",
    "\tdef is_docker_env(self):\n",
    "\t\tpath = '/proc/self/cgroup'\n",
    "\t\treturn (os.path.exists('/.dockerenv') or os.path.isfile(path) and\n",
    "\t\t\t\tany('docker' in line for line in open(path)))\n",
    "\n",
    "#Reviewing\n",
    "errorcodes = ut.arr_to_pd([\n",
    "\t{'ErrorCodes':1,'Description':'Error manually reviewing the context'},\n",
    "\t{'ErrorCodes':2,'Description':'Issue with checking the context'},\n",
    "\t{'ErrorCodes':3,'Description':'Not enough given context'},\n",
    "])\n",
    "\n",
    "def grab_context(file_name, line_num, check:bool=False):\n",
    "\tfile_name = \"/tests\" + file_name\n",
    "\tif check:\n",
    "\t\tprint(file_name)\n",
    "\treturn ut.retrieve_context(file_name, line_num, patternmatch=ut.import_global_context)\n",
    "\n",
    "\n",
    "def check(cur_row, lines_for_context:int=5):\n",
    "\trule_info, message, context, line = cur_row['cryptolationID'], cur_row['Message'], cur_row['context'], cur_row['Line']\n",
    "\tTP,TN,FP,FN = 0,0,0,0\n",
    "\tcontext_lines_len = len(context.split('\\n'))\n",
    "\n",
    "\tprint(f\"\"\"\n",
    "Current Rule :> {rule_info}\n",
    "Message\t  :> {message}\n",
    "Error @\t  :> {line}\n",
    "# of Lines   :> {context_lines_len}\n",
    "\n",
    "{context}\n",
    "============================================================================================\n",
    "\"\"\")\n",
    "\n",
    "\tif lines_for_context >  context_lines_len:\n",
    "\t\tprint(f\"The context only has {context_lines_len}, not the minimum {lines_for_context}\")\n",
    "\t\ttime.sleep(1)\n",
    "\t\treturn (3,3,3,3)\n",
    "\n",
    "\tresponse = ut.to_int(input(\"Is this a {0}:TP / 1:FP / 2:TN / 3:FN / 4:Err?\"))\n",
    "\tif response == None or response not in [0,1,2,3,4]:\n",
    "\t\tresponse = 0\n",
    "\n",
    "\tif   response in [0,4]: #TP\n",
    "\t\tTP = 1\n",
    "\telif response in [1,4]: #FP\n",
    "\t\tFP = 1\n",
    "\telif response in [2,4]: #TN\n",
    "\t\tTN = 1\n",
    "\telif response in [3,4]: #FN\n",
    "\t\tFN = 1\n",
    "\n",
    "\n",
    "\t\"\"\"\n",
    "\treturn {\n",
    "\t\t\"TP\":TP,\n",
    "\t\t\"TN\":TN,\n",
    "\t\t\"FP\":FP,\n",
    "\t\t\"FN\":FN\n",
    "\t}\"\"\"\n",
    "\treturn (TP,TN,FP,FN)\n",
    "\n",
    "\n",
    "row_listing,errors = [],[]\n",
    "\n",
    "\n",
    "def to_review(row):\n",
    "\tcheck_one = row['ProjectType'] in [\"Benchmark\",\"Top-Ranked\"]\n",
    "\tcheck_two = row['IsVuln']\n",
    "\tcheck_three = ut.is_not_empty(row['cryptolationID'])\n",
    "\n",
    "\treturn check_one and check_two and check_three\n",
    "\n",
    "def review_frame(frame: pd.DataFrame):\n",
    "\tfor cur_row in frame.itertuples():\n",
    "\t\trow = cur_row._asdict()\n",
    "\t\ttry:\n",
    "\t\t\tif ut.is_empty(row['context']) and row['IsVuln']: \n",
    "\t\t\t\trow['context'] = grab_context(row['qual_name'], ut.to_int(row['Line']))\n",
    "\t\texcept Exception as e:\n",
    "\t\t\terrors += [{\n",
    "\t\t\t\t'FileName':row['qual_name'],\n",
    "\t\t\t\t'QualLoc':row['FullQualName'],\n",
    "\t\t\t\t'Location':0,\n",
    "\t\t\t\t'Exception':str(e),\n",
    "\t\t\t}]\n",
    "\n",
    "\t\t#Already checked\n",
    "\t\ttry:\n",
    "\t\t\tif to_review(row):\n",
    "\t\t\t\trow['TP'],row['TN'],row['FP'],row['FN'] = check(row)\n",
    "\t\texcept Exception as e:\n",
    "\t\t\trow['TP'],row['TN'],row['FP'],row['FN'] = 2,2,2,2  \n",
    "\t\t\terrors += [{\n",
    "\t\t\t\t'FileName':row['qual_name'],\n",
    "\t\t\t\t'QualLoc':row['FullQualName'],\n",
    "\t\t\t\t'Location':1,\n",
    "\t\t\t\t'Exception':str(e),\n",
    "\t\t\t}]\n",
    "\n",
    "\t\trow_listing += [row]\n",
    "\treturn ut.arr_to_pd(row_listing)\n",
    "#Reviewing\n",
    "\n",
    "def downthemall():\n",
    "\timport Bandit as bandit\n",
    "\timport Licma as licma\n",
    "\timport DLint as dlint\n",
    "\timport Semgrep as semgrep\n",
    "\timport Cryptolation as cryptolation\n",
    "\tapplications = [bandit.application(), dlint.application(), licma.application(), semgrep.application(), cryptolation.application()]\n",
    "\tfor scan in applications:\n",
    "\t\tprint(scan.name())\n",
    "\t\tprint(scan.download())\n",
    "\treturn applications\n",
    "\n",
    "def modules(applications=None):\n",
    "\tif applications is None:\n",
    "\t\tapplications = downthemall()\n",
    "\n",
    "\treturn {app.name(): app.get_modules for app in applications}\n",
    "\n",
    "def match_data(sheet, _x:str='ToolName', _y:str='Module'):\n",
    "\tdiscovered = []\n",
    "\n",
    "\ttools = list(sheet[_x].unique())\n",
    "\tfor mod in list(sheet[_y].unique()):\n",
    "\t\ttemp = {\n",
    "\t\t\t'Module':mod,\n",
    "\t\t\t'Count':sheet[ (sheet[_y] == mod) ].shape[0]\n",
    "\t\t}\n",
    "\t\tin_tools = 0\n",
    "\t\tfor tool in tools:\n",
    "\t\t\tsearched = list(sheet[ (sheet[_x] == tool) ][_y])\n",
    "\t\t\tcontains = mod in searched or any(x.startswith(mod) for x in searched) \n",
    "\n",
    "\t\t\ttemp[tool] = contains\n",
    "\t\t\tin_tools += int(contains)\n",
    "\n",
    "\t\ttemp[\"InTools\"] = in_tools\n",
    "\n",
    "\t\tdiscovered += [\n",
    "\t\t\ttemp\n",
    "\t\t]\n",
    "\treturn ut.arr_to_pd(discovered)\n",
    "\n",
    "def bare_break_down(name, mod_string):\n",
    "\toutput = []\n",
    "\n",
    "\trunning = \"\"\n",
    "\tfor sub_mod in mod_string.split(\".\"):\n",
    "\t\trunning += sub_mod\n",
    "\t\toutput += [{\n",
    "\t\t\t'ToolName':name,\n",
    "\t\t\t'Module':running\n",
    "\t\t}]\n",
    "\t\trunning += \".\"\n",
    "\n",
    "\treturn ut.arr_to_pd(output)\n",
    "\n",
    "def breaking_down_modules(apps=pd.DataFrame()):\n",
    "\toutput = []\n",
    "\n",
    "\tfor app, app_mods in modules(apps).items():\n",
    "\t\tfor app_mod in list(set(app_mods)):\n",
    "\t\t\toutput += ut.pd_to_arr(bare_break_down(app, app_mod))\n",
    "\n",
    "\treturn ut.arr_to_pd(output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tcmd, args, exe, printy = [], set(map(lambda x: x.lower().strip(), sys.argv)), False, []\n",
    "\n",
    "\tif any({\"python\", \"run\", \"scan\"} & args):\n",
    "\t\tcmd = [\n",
    "\t\t\t'jupyter nbconvert LiveTests.ipynb --to python',\n",
    "\t\t\t#'jupyter nbconvert LiveTests.ipynb --to python', 'ipython LiveTests.py', 'rm LiveTests.py'\n",
    "\t\t\t#'jupyter nbconvert --execute --to notebook --inplace --allow-errors --ExecutePreprocessor.timeout=-1 LiveTests.ipynb'\n",
    "\t\t]\n",
    "\t\tprinty = ['ipython3 --no-banner --no-confirm-exit --quick -i LiveTests.py']\n",
    "\telif any({\"docker\", \"build\"} & args):\n",
    "\t\tindicateBase()\n",
    "\t\ttry_fail(f\"echo DATA={os.path.abspath(os.curdir)} > env.txt\")\n",
    "\t\tprinty = [\n",
    "\t\t\tdocker_base +\n",
    "\t\t\t' run --rm -it  -v \"`pwd`:/sync\" -v ' + get_docker_connect() +\n",
    "\t\t\t':/var/run/docker.sock  frantzme/pytesting:latest'\n",
    "\t\t]\n",
    "\telif \"clean\" in args:\n",
    "\t\tcmd = [\n",
    "\t\t    \"rm *.txt\", \"rm *.csv\", \"rm *.pkl\", \"rm Makefile\", \"rm *.xlsx.zip\",\n",
    "\t\t    \"rm *.xlsx\", \"rm *_SPLIT_*py\", \"rm *.json\", \"rm TEMP_*\",\n",
    "\t\t    \"rm LiveTests.py\",\n",
    "\t\t    \"find . -maxdepth 1 -type d -name '[a-zA-Z]*' -exec rm -r {} \\;\"\n",
    "\t\t]\n",
    "\telif any({\"downall\"} & args):\n",
    "\t\tdownthemall()\n",
    "\telif any({\"modules\"} & args):\n",
    "\t\tos.system(f\"apt-get update && yes|apt-get install wget\")\n",
    "\t\tapplications = downthemall()\n",
    "\t\tbreaking_down_modules(applications).to_csv(\"modules.csv\", index=False)\n",
    "\t\tfor app in applications:\n",
    "\t\t\tfor dl_files in app.dl_files:\n",
    "\t\t\t\tcmd += [\n",
    "\t\t\t\t\tf\"yes|rm -r {dl_files}\"\n",
    "\t\t\t\t]\n",
    "\telif any({\"semgrep_info\"} & args):\n",
    "\t\tos.system(f\"apt-get update && yes|apt-get install wget\")\n",
    "\t\timport json\n",
    "\t\timport Semgrep\n",
    "\t\tsemgrep = Semgrep.application()\n",
    "\n",
    "\t\tsaved_file, contents = \"semgrep_contents.json\", None\n",
    "\n",
    "\t\tif not os.path.exists(saved_file):\n",
    "\t\t\tsemgrep.download()\n",
    "\t\t\tcontents = semgrep.grab_contents\n",
    "\t\telse:\n",
    "\t\t\twith open(\"semgrep_contents.json\",\"w+\") as writer:\n",
    "\t\t\t\tcontents = json.load(writer)\n",
    "\n",
    "\t\tmapped = []\n",
    "\t\tfor x in contents:\n",
    "\t\t\tmapped += semgrep.content_property(x)\n",
    "\n",
    "\t\tut.arr_to_pd(mapped).to_csv(\"SemGrep_Identifiable_Info.csv\")\n",
    "\telif any({\"test_info\"} & args):\n",
    "\t\tfolder_name = \"00_ToScan\"\n",
    "\t\tdir_to_check = os.path.join(os.path.abspath(os.curdir),folder_name)\n",
    "\t\tdir_check_name = dir_to_check+\"/\"\n",
    "\t\tfiltered_by_folder = lambda foil: foil.replace(os.path.basename(foil),'') != dir_check_name\n",
    "\t\ttest_module_info = []\n",
    "\n",
    "\t\tcontainer = []\n",
    "\t\tfor foil in ut.file_by_type(dir_to_check,\".py\"):\n",
    "\t\t\tprint(foil)\n",
    "\t\t\tif filtered_by_folder(foil) and \"ipynb\" not in foil:\n",
    "\t\t\t\tfolder_disection = foil.replace(os.path.basename(foil),'').replace(dir_check_name,'').replace('/','')\n",
    "\t\t\t\tpattern_type, test_type = folder_disection.split('_')\n",
    "\t\t\t\thas_pattern = pattern_type == 'pattern'\n",
    "\n",
    "\t\t\t\tfoil_name = os.path.basename(foil)\n",
    "\t\t\t\trule = int(foil_name.split('rule_')[-1].split('_')[0])\n",
    "\t\t\t\tis_fieldsensitive = 'Field-Sensitive' in foil_name\n",
    "\t\t\t\tis_global = 'Global' in foil_name\n",
    "\t\t\t\tis_interprocedural = 'Interprocedural' in foil_name\n",
    "\t\t\t\tis_dblinterprocedural = 'InterproceduralViaReturn' in foil_name\n",
    "\t\t\t\tis_pathsensitive = 'Path-Sensitive' in foil_name\n",
    "\n",
    "\t\t\t\twith open(foil,'r') as reader:\n",
    "\t\t\t\t\tcontents = ''.join(reader.readlines())\n",
    "\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\timports = ':'.join([__.argval for __ in dis.get_instructions(contents) if 'IMPORT_NAME' in __.opname])\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(f\"Error reading the file:> {e}\")\n",
    "\t\t\t\t\tprint(contents)\n",
    "\t\t\t\t\tprint(\"=\"*15)\n",
    "\t\t\t\t\timports = None\n",
    "\t\t\t\t\twhile ut.is_empty(imports):\n",
    "\t\t\t\t\t\timports = input(\"Please manually enter all of the base import names delimited by a colon:> \").strip()\n",
    "\t\t\t\t\t\tprint()\n",
    "\n",
    "\t\t\t\t\tprint(\"=\"*20)\n",
    "\n",
    "\t\t\t\tfor imp in imports.split(':'):\n",
    "\t\t\t\t\ttest_module_info += ut.pd_to_arr(bare_break_down(foil, imp))\n",
    "\n",
    "\t\t\t\tcontainer += [{\n",
    "\t\t\t\t\t'FileName':foil_name,\n",
    "\t\t\t\t\t'FileDir':os.path.dirname(foil).replace(dir_check_name,''),\n",
    "\t\t\t\t\t'Rule':rule,\n",
    "\t\t\t\t\t'HasPattern':has_pattern,\n",
    "\t\t\t\t\t'TestType':test_type,\n",
    "\t\t\t\t\t\"FieldSensitive\":is_fieldsensitive,\n",
    "\t\t\t\t\t\"Global\":is_global,\n",
    "\t\t\t\t\t\"InterProcedural\":is_interprocedural,\n",
    "\t\t\t\t\t\"DBLInterprocedural\":is_dblinterprocedural,\n",
    "\t\t\t\t\t\"PathSensitive\":is_pathsensitive,\n",
    "\n",
    "\t\t\t\t\t\"FieldSensitive_INT\":int(is_fieldsensitive),\n",
    "\t\t\t\t\t\"Global_INT\":int(is_global),\n",
    "\t\t\t\t\t\"InterProcedural_INT\":int(is_interprocedural),\n",
    "\t\t\t\t\t\"DBLInterprocedural_INT\":int(is_dblinterprocedural),\n",
    "\t\t\t\t\t\"PathSensitive_INT\":int(is_pathsensitive),\n",
    "\n",
    "\t\t\t\t\t\"Runnable\": None,#is_runnable(foil),\n",
    "\t\t\t\t\t\"Imports\":imports,\n",
    "\t\t\t\t\t\"Contents\":contents\n",
    "\t\t\t\t}]\n",
    "\t\tut.arr_to_pd(container).to_csv(f\"{folder_name}_FileInfo_Container.csv\")\n",
    "\t\tut.arr_to_pd(test_module_info).to_csv(f\"{folder_name}_TestModule.csv\")\n",
    "\telif any({\"merged_test_info\"} & args):\n",
    "\t\t\"\"\"\n",
    "\t\tGrabbing the modules from the files\n",
    "\t\t\"\"\"\n",
    "\t\tos.system(f\"apt-get update && yes|apt-get install wget p7zip-full\")\n",
    "\t\tapplications = downthemall()\n",
    "\t\tapplication_modules = breaking_down_modules(applications)\n",
    "\n",
    "\t\tfrom pprint import pprint\n",
    "\t\tfor app in application_modules:\n",
    "\t\t\tpprint(app)\n",
    "\n",
    "\t\tif input(\"Continue? [y/n]> \").strip().lower() != 'y':\n",
    "\t\t\tsys.exit(-1)\n",
    "\n",
    "\t\tfolder_name = \"00_ToScan\"\n",
    "\t\tdir_to_check = os.path.join(os.path.abspath(os.curdir),folder_name)\n",
    "\t\tdir_check_name = dir_to_check+\"/\"\n",
    "\t\tfiltered_by_folder = lambda foil: foil.replace(os.path.basename(foil),'') != dir_check_name\n",
    "\t\ttest_module_info = []\n",
    "\n",
    "\t\tcontainer = []\n",
    "\t\tfor foil in ut.file_by_type(dir_to_check,\".py\"):\n",
    "\t\t\tprint(foil)\n",
    "\t\t\tif filtered_by_folder(foil) and \"ipynb\" not in foil:\n",
    "\t\t\t\twith open(foil,'r') as reader:\n",
    "\t\t\t\t\tcontents = ''.join(reader.readlines())\n",
    "\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\timports = ':'.join([__.argval for __ in dis.get_instructions(contents) if 'IMPORT_NAME' in __.opname])\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(f\"Error reading the file:> {e}\")\n",
    "\t\t\t\t\tprint(contents)\n",
    "\t\t\t\t\tprint(\"=\"*15)\n",
    "\t\t\t\t\timports = None\n",
    "\t\t\t\t\twhile ut.is_empty(imports):\n",
    "\t\t\t\t\t\timports = input(\"Please manually enter all of the base import names delimited by a colon:> \").strip()\n",
    "\t\t\t\t\t\tprint()\n",
    "\n",
    "\t\t\t\t\tprint(\"=\"*20)\n",
    "\n",
    "\t\t\t\tfor imp in imports.split(':'):\n",
    "\t\t\t\t\ttest_module_info += ut.pd_to_arr(bare_break_down(foil, imp))\n",
    "\n",
    "\t\ttests_pd = ut.arr_to_pd(test_module_info)\n",
    "\t\tif list(application_modules.columns) != list(tests_pd.columns):\n",
    "\t\t\tprint(\"The keys are not the same\")\n",
    "\t\t\tprint(application_modules.columns)\n",
    "\t\t\tprint(tests_pd.columns)\n",
    "\t\t\tsys.exit(0)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"This next step make take a little while\")\n",
    "\t\t\tmerged = ut.arr_to_pd( ut.pd_to_arr(application_modules) + ut.pd_to_arr(tests_pd) )\n",
    "\n",
    "\t\tmerged.to_csv(f\"Merged_Test_Info.csv\")\n",
    "\t\tcur_matched = match_data(merged).to_csv(f\"Merged_Matched.csv\")\n",
    "\t\twith ut.xcyl(\"Combination.xlsx\") as writer:\n",
    "\t\t\twriter.add_frame(\"Merged_Test_Info\", merged)\n",
    "\t\t\twriter.add_frame(\"Merged_Matched\", cur_matched)\n",
    "\n",
    "\t\tfor app in applications:\n",
    "\t\t\tfor dl_files in app.dl_files:\n",
    "\t\t\t\tcmd += [\n",
    "\t\t\t\t\tf\"yes|rm -r {dl_files}\"\n",
    "\t\t\t\t]\n",
    "\tfor run_cmd in cmd:\n",
    "\t\tprint(run_cmd);try_fail(run_cmd)\n",
    "\tfor run_cmd in printy:\n",
    "\t\tprint(run_cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ut.set_mito()\n",
    "botID,chatID = \"2130746695:AAHzqwcww-3d5sZmHmds1fG41WDIFeJgTlc\",\"656252903\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_types = {\n",
    "\t\"projecttype\":str,\n",
    "\t\"projectname\":str,\n",
    "\t\"projecturl\":str,\n",
    "\t\"qual_name\":str,\n",
    "\t\"tool_name\":str,\n",
    "\t\"time_taken\":int,\n",
    "\t\"Program_Lines\":int,\n",
    "\t\"Total_Lines\":int,\n",
    "\t\"Number_of_Imports\":str, \n",
    "\t\"MCC\":int,\n",
    "\t\"IsVuln\":bool,\n",
    "\t\"Name\":str,\n",
    "\t\"OG_ID\":str,\n",
    "\t\"cryptolationID\":int,\n",
    "\t\"Message\":str,\n",
    "\t\"Line\":int,\n",
    "\t\"severity\":str,\n",
    "\t\"extra_info\":str,\n",
    "\t\"confidence\":str,\n",
    "\t\"context\":str,\n",
    "\t\"TP\":int,\n",
    "\t\"FP\":int,\n",
    "\t\"TN\":int,\n",
    "\t\"FN\":int\n",
    "}\n",
    "\n",
    "def gen(\n",
    "\tprojecttype=np.NaN,\n",
    "\tprojectname=np.NaN,\n",
    "\tprojecturl=np.NaN,\n",
    "\tqual_name=np.NaN,\n",
    "\ttool_name=np.NaN,\n",
    "\ttime_taken=np.NaN,\n",
    "\tProgram_Lines=np.NaN,\n",
    "\tTotal_Lines=np.NaN,\n",
    "\tNumber_of_Imports=np.NaN,\n",
    "\tMCC=np.NaN,\n",
    "\tIsVuln=np.NaN,\n",
    "\tName=np.NaN,\n",
    "\tOG_ID=np.NaN,\n",
    "\tcryptolationID=np.NaN,\n",
    "\tMessage=np.NaN,\n",
    "\tLine=np.NaN,\n",
    "\tseverity=np.NaN,\n",
    "\textra_info=np.NaN,\n",
    "\tconfidence=np.NaN,\n",
    "\tcontext=np.NaN,\n",
    "\tTP=np.NaN,\n",
    "\tFP=np.NaN,\n",
    "\tTN=np.NaN,\n",
    "\tFN=np.NaN,\n",
    "\tMETRIC_FILE=\"None\"\n",
    "):\n",
    "\tif isinstance(METRIC_FILE,pd.DataFrame):\n",
    "\t\tdyct = METRIC_FILE.to_dict()\n",
    "\t\tdef grab(val):\n",
    "\t\t\tif val in dyct and dyct[val] != {}:\n",
    "\t\t\t\treturn dyct[val][0]\n",
    "\t\t\treturn np.NaN\n",
    "\t\t\n",
    "\t\treturn {\n",
    "\t\t\t\"projecttype\":ut.to_int(ut.from_nan(projecttype) or grab('projecttype'),return_self=True),\n",
    "\t\t\t\"projectname\":ut.to_int(ut.from_nan(projectname) or grab('projectname'),return_self=True),\n",
    "\t\t\t\"projecturl\":ut.to_int(ut.from_nan(projecturl) or grab('projecturl'),return_self=True),\n",
    "\t\t\t\"qual_name\":ut.to_int(ut.from_nan(qual_name) or grab('qual_name'),return_self=True),\n",
    "\t\t\t\"tool_name\":ut.to_int(ut.from_nan(tool_name) or grab('tool_name'),return_self=True),\n",
    "\t\t\t\"time_taken\":ut.to_int(ut.from_nan(time_taken) or grab('time_taken'),return_self=True),\n",
    "\t\t\t\"Program_Lines\":ut.to_int(ut.from_nan(Program_Lines) or grab('Program_Lines'),return_self=True),\n",
    "\t\t\t\"Total_Lines\":ut.to_int(ut.from_nan(Total_Lines) or grab('Total_Lines'),return_self=True),\n",
    "\t\t\t\"Number_of_Imports\":ut.to_int(ut.from_nan(Number_of_Imports) or grab('Number_of_Imports'),return_self=True),\n",
    "\t\t\t\"MCC\":ut.to_int(ut.from_nan(MCC) or grab('MCC'),return_self=True),\n",
    "\t\t\t\"IsVuln\":ut.to_int(ut.from_nan(IsVuln) or grab('IsVuln'),return_self=True),\n",
    "\t\t\t\"Name\":ut.to_int(ut.from_nan(Name) or grab('Name'),return_self=True),\n",
    "\t\t\t\"OG_ID\":ut.to_int(ut.from_nan(OG_ID) or grab('OG_ID'),return_self=True),\n",
    "\t\t\t\"cryptolationID\":ut.to_int(ut.from_nan(cryptolationID) or grab('cryptolationID'),return_self=True),\n",
    "\t\t\t\"Message\":ut.to_int(ut.from_nan(Message) or grab('Message'),return_self=True),\n",
    "\t\t\t\"Line\":ut.to_int(ut.from_nan(Line) or grab('Line'),return_self=True),\n",
    "\t\t\t\"severity\":ut.to_int(ut.from_nan(severity) or grab('severity'),return_self=True),\n",
    "\t\t\t\"extra_info\":ut.to_int(ut.from_nan(extra_info) or grab('extra_info'),return_self=True),\n",
    "\t\t\t\"confidence\":ut.to_int(ut.from_nan(confidence) or grab('confidence'),return_self=True),\n",
    "\t\t\t\"context\":ut.to_int(ut.from_nan(context) or grab('context'),return_self=True),\n",
    "\t\t\t\"TP\":ut.to_int(ut.from_nan(TP) or grab('TP'),return_self=True),\n",
    "\t\t\t\"FP\":ut.to_int(ut.from_nan(FP) or grab('FP'),return_self=True),\n",
    "\t\t\t\"TN\":ut.to_int(ut.from_nan(TN) or grab('TN'),return_self=True),\n",
    "\t\t\t\"FN\":ut.to_int(ut.from_nan(FN) or grab('FN'),return_self=True)\n",
    "\t\t}\n",
    "\telse:\n",
    "\t\treturn {\n",
    "\t\t\t\"projecttype\":ut.to_int(projecttype,return_self=True),\n",
    "\t\t\t\"projectname\":ut.to_int(projectname,return_self=True),\n",
    "\t\t\t\"projecturl\":ut.to_int(projecturl,return_self=True),\n",
    "\t\t\t\"qual_name\":ut.to_int(qual_name,return_self=True),\n",
    "\t\t\t\"tool_name\":ut.to_int(tool_name,return_self=True),\n",
    "\t\t\t\"time_taken\":ut.to_int(time_taken,return_self=True),\n",
    "\t\t\t\"Program_Lines\":ut.to_int(Program_Lines,return_self=True),\n",
    "\t\t\t\"Total_Lines\":ut.to_int(Total_Lines,return_self=True),\n",
    "\t\t\t\"Number_of_Imports\":ut.to_int(Number_of_Imports,return_self=True),\n",
    "\t\t\t\"MCC\":ut.to_int(MCC,return_self=True),\n",
    "\t\t\t\"IsVuln\":ut.to_int(IsVuln,return_self=True),\n",
    "\t\t\t\"Name\":ut.to_int(Name,return_self=True),\n",
    "\t\t\t\"OG_ID\":ut.to_int(OG_ID,return_self=True),\n",
    "\t\t\t\"cryptolationID\":ut.to_int(cryptolationID,return_self=True),\n",
    "\t\t\t\"Message\":ut.to_int(Message,return_self=True),\n",
    "\t\t\t\"Line\":ut.to_int(Line,return_self=True),\n",
    "\t\t\t\"severity\":ut.to_int(severity,return_self=True),\n",
    "\t\t\t\"extra_info\":ut.to_int(extra_info,return_self=True),\n",
    "\t\t\t\"confidence\":ut.to_int(confidence,return_self=True),\n",
    "\t\t\t\"context\":ut.to_int(context,return_self=True),\n",
    "\t\t\t\"TP\":ut.to_int(TP,return_self=True),\n",
    "\t\t\t\"FP\":ut.to_int(FP,return_self=True),\n",
    "\t\t\t\"TN\":ut.to_int(TN,return_self=True),\n",
    "\t\t\t\"FN\":ut.to_int(FN,return_self=True)\n",
    "\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_out(raw_msg,logger_file=f\".logging_file_{ut.cur_time}.csv\"):\n",
    "\tlog_msg = ut.cur_time_ms() + \" , \" + raw_msg\n",
    "\twith open(logger_file, \"a+\") as appender:\n",
    "\t\tappender.write(log_msg+\"\\n\")\n",
    "\tprint(log_msg)\n",
    "\treturn\n",
    "\n",
    "disp = lambda _input: write_out(_input)\n",
    "disp_msg = lambda _input: disp(_input)\n",
    "\n",
    "def settypes(df,hard_set=False):\n",
    "\tfor col in data_types.keys():\n",
    "\t\tsub_type = data_types[col]\n",
    "\t\t_set = hard_set\n",
    "\t\tif sub_type == bool:\n",
    "\t\t\tdf[col]=df[col].fillna(False)\n",
    "\t\t\t_set = True\n",
    "\t\telif sub_type == int:\n",
    "\t\t\tif _set:\n",
    "\t\t\t\tdf[col]=df[col].fillna(-1)\n",
    "\t\telif sub_type == str:\n",
    "\t\t\tdf[col]=df[col].fillna('')\n",
    "\t\t\t_set = True\n",
    "\t\t\n",
    "\t\tif _set:\n",
    "\t\t\tdf[col] = df[col].astype(sub_type)\n",
    "\tdf.set_index(['qual_name','Line','tool_name'])\n",
    "\treturn df\n",
    "\n",
    "ut.run(\"rm *.logging_file_*.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Materials Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_json_files = False\n",
    "folder_name = \"00_ToScan\"\n",
    "if use_json_files:\n",
    "\tprepare = None\n",
    "else:\n",
    "\tprepare = [{\n",
    "\t\tfolder_name:{'url': None, 'tag': None, 'commit': None}\n",
    "\t}]\n",
    "\n",
    "\n",
    "if use_json_files:\n",
    "\tfull_libraries = re(\"*.json\")\n",
    "else:\n",
    "\tfull_libraries = prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "disp_msg(\"Starting to warm up the apps\")\n",
    "metrics, scanners = [], []\n",
    "\n",
    "scanners += [semgrep.application()]\n",
    "metrics += [pymetrics.application()]\n",
    "metrics_name = \"METRICS\"\n",
    "\n",
    "applications = metrics + scanners\n",
    "\n",
    "disp_msg(\"Loaded up the apps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_repos, extra_logging, raw_timing, scanningExceptions = set(), prepare is None, [], []\n",
    "golden_standard = \"PyMetrics\"\n",
    "\n",
    "def add_exception(name, proj_name, break_time):\n",
    "\tglobal scanningExceptions\n",
    "\tscanningExceptions += [ut.dyct_frame({\n",
    "\t\t\"Time\": ut.cur_time_ms(),\n",
    "\t\t\"App\": f\"{name}\",\n",
    "\t\t\"Proj\": f\"{proj_name}\",\n",
    "\t\t\"Exception\": f\"Time out at {break_time} seconds\"\n",
    "\t})]\n",
    "\n",
    "def add_timing(proj_name, tool_name, time):\n",
    "\tglobal raw_timing\n",
    "\traw_timing += [ut.dyct_frame({\n",
    "\t\t\t'ProjectName':proj_name,\n",
    "\t\t\t'ToolName':tool_name,\n",
    "\t\t\t'Time (s)':time\n",
    "\t})]\n",
    "\n",
    "empty_frame = lambda:pd.DataFrame([gen()],columns=data_types.keys())\n",
    "\n",
    "current_contents = {\n",
    "\t'Standard':None,\n",
    "\t'Overall':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for app in applications:\n",
    "\tdisp_msg(f\"Installing App {app.name()}\")\n",
    "\tapp.install()\n",
    "\tdisp_msg(f\"Finishing  App {app.name()}: {app.version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Raw Execution of Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for app_itr, app in enumerate(applications):\n",
    "\tname = app.name() if app in scanners else metrics_name\n",
    "\tprint(f\"Currently working on app {app.name()}\")\n",
    "\tcurrent_contents[app.name()] = []\n",
    "\n",
    "\tfor LibraryValue in ut.progressBar( dc(full_libraries) ):\n",
    "\t\tif use_json_files:\n",
    "\t\t\twith open(LibraryValue,'r') as reader:\n",
    "\t\t\t\tdictionary = json.load(reader)\n",
    "\t\telse:\n",
    "\t\t\tdictionary = LibraryValue\n",
    "\n",
    "\t\tappend = []\n",
    "\t\tfor proj_itr, (proj_name,proj_value) in enumerate(dictionary.items()):\n",
    "\t\t\tproj_url, proj_tag, proj_commit = proj_value['url'] , proj_value['tag'], proj_value['commit']\n",
    "\n",
    "\t\t\twith ut.GRepo(proj_name, proj_url, proj_tag, proj_commit, delete=proj_url is not None, silent=False, local_dir = False) as repo:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\t@timeout(time_limit=60 * 10) #10 minutes timeout\n",
    "\t\t\t\t\tdef scannr(proj_name, app, app_name:str, proj_url:str):\n",
    "\t\t\t\t\t\treturn app.scan(proj_name,True), True\n",
    "\t\t\t\t\t(app_results,app_timing),successfully_scanned = scannr(proj_name=proj_name, app=app, app_name=app.name(), proj_url=proj_url)\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tsuccessfully_scanned, app_timing = False, -1\n",
    "\t\t\t\t\tadd_exception(name, proj_name, 600)\n",
    "\t\t\t\t\tpass\n",
    "\n",
    "\t\t\t\tadd_timing(proj_name, app.name(), app_timing)\n",
    "\t\t\t\tapp_set_types = settypes(app.mapp(app_results,proj_name,columns=data_types.keys(),gen=gen,time_taken=app_timing)) if successfully_scanned else empty_frame()\n",
    "\n",
    "\t\t\t\tapp_set_types.to_csv(f\"{app.name()}_{proj_name}_FULLYSCAN.csv\")\n",
    "\t\t\t\tcurrent_contents[app.name()] = ut.frame_dycts(app_set_types)\n",
    "\n",
    "\t\t\t\tfor row in current_contents[app.name()]:\n",
    "\n",
    "\t\t\t\t\tif git_info := get_git(proj_name):\n",
    "\t\t\t\t\t\trow['GIT_commit'] = git_info['commit']\n",
    "\t\t\t\t\t\trow['GIT_tree'] = git_info['tree']\n",
    "\t\t\t\t\t\trow['GIT_parent'] = git_info['parent']\n",
    "\t\t\t\t\t\trow['GIT_author'] = git_info['author']\n",
    "\t\t\t\t\t\trow['GIT_author_date'] = git_info['author_date']\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\trow['GIT_commit'] = None\n",
    "\t\t\t\t\t\trow['GIT_tree'] = None\n",
    "\t\t\t\t\t\trow['GIT_parent'] = None\n",
    "\t\t\t\t\t\trow['GIT_author'] = None\n",
    "\t\t\t\t\t\trow['GIT_author_date'] = None\n",
    "\n",
    "\t\t\t\t\tfor key,value in repo.get_info().items():\n",
    "\t\t\t\t\t\trow[\"REPO_\"+key] = value\n",
    "\n",
    "\t\t\t\tprint(f\"Current App :> {app.name()}\")\n",
    "\t\t\t\tif app.name(golden_standard):\n",
    "\t\t\t\t\tcurrent_contents['Standard'] = app_set_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Post Execution Prettifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merging and collecting and dropped files by scanning tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Picking up any non scanned or itemized files\n",
    "for app_itr, app in enumerate(applications):\n",
    "\tif app.name(golden_standard):\n",
    "\t\tfor golden_standard_row in current_contents[app.name()]:\n",
    "\t\t\tcurrent_contents['Overall'] += [golden_standard_row]\n",
    "\t\tcontinue\n",
    "\n",
    "\tcurrent_set_to_clear = dc(current_contents['Standard'])\n",
    "\tdef check_remove(qual_name):\n",
    "\t\toutput = None\n",
    "\t\tfor sub_row in current_set_to_clear.itertuples():\n",
    "\t\t\trow = sub_row._asdict()\n",
    "\t\t\tif row['qual_name'] == qual_name:\n",
    "\t\t\t\toutput = sub_row\n",
    "\t\t\t\tbreak\n",
    "\t\tif output is not None:\n",
    "\t\t\tcurrent_set_to_clear.drop(current_set_to_clear.index[output.Index])\n",
    "\t\t\toutput = output._asdict()\n",
    "\t\treturn output\n",
    "\n",
    "\tfor current_scanned_file in current_contents[app.name()]:\n",
    "\t\tif alive_value := check_remove(current_scanned_file['qual_name']):\n",
    "\n",
    "\t\t\tfor key in ['Total_Lines', 'Program_Lines', 'Number_of_Imports', 'MCC']:\n",
    "\t\t\t\tcurrent_scanned_file[key] = alive_value[key]\n",
    "\t\telse:\n",
    "\t\t\tfor key in ['Total_Lines', 'Program_Lines', 'Imports', 'MCC']:\n",
    "\t\t\t\tcurrent_scanned_file[key] = -10\n",
    "\n",
    "\t\tfile_name, line = current_scanned_file['qual_name'], current_scanned_file['Line']\n",
    "\t\tcurrent_scanned_file['Context']  = ut.retrieve_context(file_name, line, 5,ut.import_global_context)\n",
    "\n",
    "\t\tcurrent_contents['Overall'] += [current_scanned_file]\n",
    "\n",
    "\tfor unfound_file_raw in current_set_to_clear.itertuples():\n",
    "\t\tunfound_file = unfound_file_raw._asdict()\n",
    "\t\tunfound_file['tool_name'] = app.name()\n",
    "\t\tunfound_file['vuln'] = False\n",
    "\t\tcurrent_contents['Overall'] += [unfound_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('raw_save.json','w+') as writer:\n",
    "\tjson.dump(current_contents['Overall'], writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Total Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallContainer =  pd.DataFrame() if len(current_contents['Overall']) == 0 else ut.arr_to_pd(current_contents['Overall'])\n",
    "timing = pd.DataFrame() if len(raw_timing) == 0 else ut.arr_to_pd(raw_timing)\n",
    "scanningException = pd.DataFrame() if len(scanningExceptions) == 0 else ut.arr_to_pd(scanningExceptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Post Mortem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (frame,name) in [\n",
    "\t(overallContainer, 'FullyScanned'),\n",
    "\t(timing, 'OverallTiming'),\n",
    "\t(scanningException, 'ScanningExceptions')\n",
    "]:\n",
    "\tfor output_type in [\"csv\",\"pkl\"]:\n",
    "\t\tut.save_frames(frame,ut.clean_string(name),output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "foil_name = \"Finalized_Results\"\n",
    "with ut.telegramBot(botID,chatID) as bot:\n",
    "\tif not foil_name.endswith(\".xlsx\"):\n",
    "\t\tfoil_name = foil_name + \".xlsx\"\n",
    "\twith ut.xcyl(foil_name) as writer:\n",
    "\t\twriter.addr(\"FullResults\", overallContainer)\n",
    "\n",
    "\tbot.upload(foil_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
